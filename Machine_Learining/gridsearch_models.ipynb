{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, output_filename):\n",
    "    \"\"\"Plot confusion matrix using heatmap.\n",
    "\n",
    "    Args:\n",
    "    data (list of list): List of lists with confusion matrix data.\n",
    "    labels (list): Labels which will be plotted across x and y axis.\n",
    "    output_filename (str): Path to output file.\n",
    "\n",
    "    \"\"\"\n",
    "    sns.set(color_codes=True)\n",
    "    # plt.figure(1, figsize=(9, 6))\n",
    "\n",
    "    # plt.title(\"Confusion Matrix\")\n",
    "    labels = [\"Drossel\", \"Mosfet\", \"Normal\"]\n",
    "\n",
    "    group_percentages = [\"{0:.2%}\".format(value) for value in\n",
    "                         confusion_matrix.flatten()/np.sum(confusion_matrix)]\n",
    "    \n",
    "    group_counts = [\"{0:0.0f}\".format(value) for value in\n",
    "                    confusion_matrix.flatten()]\n",
    "    \n",
    "    xylabels = [f\"{v1}\\n{v2}\" for v1, v2 in zip(group_counts, group_percentages)]\n",
    "    xylabels = np.asarray(xylabels).reshape(3,3)\n",
    "    \n",
    "    sns.set(font_scale=1)\n",
    "    ax = sns.heatmap(confusion_matrix, annot=xylabels, fmt='', cmap=\"YlGnBu\", cbar=False)\n",
    "    # ax = sns.heatmap(confusion_matrix, annot=xylabels, fmt='', cmap=\"YlGnBu\", cbar_kws={'label': 'Scale'})\n",
    "\n",
    "    ax.set_xticklabels(labels)\n",
    "    ax.set_yticklabels(labels)\n",
    "    \n",
    "    ax.invert_yaxis()\n",
    "\n",
    "    ax.set(xlabel=\"Actual Label\", ylabel=\"Predicted Label\")\n",
    "    \n",
    "    plt.show()\n",
    " \n",
    "    # plt.savefig(output_filename, bbox_inches='tight', dpi=1000)\n",
    "    plt.savefig(output_filename, backend=\"pgf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from joblib import dump, load\n",
    "import os\n",
    "import time\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.kernel_approximation import Nystroem\n",
    "\n",
    "class GridSearch:\n",
    "    def __init__(self, clf, params) -> None:\n",
    "        self.clf = clf\n",
    "        self.params = params\n",
    "        self.grid = GridSearchCV(estimator=self.clf, param_grid=self.params, return_train_score=True, verbose=3,n_jobs=-1, cv=10)\n",
    "        self.elapsed_time = -1\n",
    "    \n",
    "    def train(self,x_train, y_train):\n",
    "        start = time.time()\n",
    "        self.grid.fit(x_train, y_train)\n",
    "        self.elapsed_time = time.time() - start\n",
    "\n",
    "    def plot_selection_process(self, save=None, path=None):\n",
    "        ## Results from grid search\n",
    "        results = self.grid.cv_results_\n",
    "        means_test = results['mean_test_score']\n",
    "        stds_test = results['std_test_score']\n",
    "        means_train = results['mean_train_score']\n",
    "        stds_train = results['std_train_score']\n",
    "        ## Getting indexes of values per hyper-parameter\n",
    "        masks=[]\n",
    "        masks_names= list(self.grid.best_params_.keys())\n",
    "        for p_k, p_v in self.grid.best_params_.items():\n",
    "            masks.append(list(results['param_'+p_k].data==p_v))\n",
    "\n",
    "        params=self.grid.param_grid\n",
    "\n",
    "        ## Ploting results\n",
    "        fig, ax = plt.subplots(1,len(params),sharex='none', sharey='none',figsize=(20,5))\n",
    "        fig.suptitle( str(self.clf)[:-2] + ': Score per parameter')\n",
    "        fig.text(0.04, 0.5, 'MEAN SCORE', va='center', rotation='vertical')\n",
    "        pram_preformace_in_best = {}\n",
    "        for i, p in enumerate(masks_names):\n",
    "            m = np.stack(masks[:i] + masks[i+1:])\n",
    "            pram_preformace_in_best\n",
    "            best_parms_mask = m.all(axis=0)\n",
    "            best_index = np.where(best_parms_mask)[0]\n",
    "            x = np.array(params[p])\n",
    "            y_1 = np.array(means_test[best_index])\n",
    "            e_1 = np.array(stds_test[best_index])\n",
    "            y_2 = np.array(means_train[best_index])\n",
    "            e_2 = np.array(stds_train[best_index])\n",
    "            ax[i].errorbar(x, y_1, e_1, linestyle='--', marker='o', label='test')\n",
    "            ax[i].errorbar(x, y_2, e_2, linestyle='-', marker='^',label='train' )\n",
    "            ax[i].set_xlabel(p.upper())\n",
    "\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        if save:\n",
    "            fig.savefig(str(path) + \"/\" + str(self.clf)[:-2] + \"_parameter_overview.pgf\")\n",
    "\n",
    "    def classification_result(self, y_train, y_test, path):\n",
    "        # grid.predict() call predict on the estimator with the best found params\n",
    "        y_pred = self.grid.predict(y_train)\n",
    "        cf_matrix = confusion_matrix(y_test, y_pred)\n",
    "        plt.figure()\n",
    "        plot_confusion_matrix(cf_matrix, (str(path) + \"/\" + str(self.clf)[:-2] + \"confusion_matrix.pgf\"))\n",
    "        self.classification_results = classification_report(y_test, y_pred, output_dict=True)\n",
    "        return self.classification_results\n",
    "\n",
    "    def plot_classification_result(self, y_train, y_test, save=None, path=None):\n",
    "        df = pd.DataFrame(self.classification_result(y_train, y_test, path))\n",
    "        df = df[[\"drossel\", \"mosfets\", \"normal\"]]\n",
    "        plt.figure()\n",
    "        if save:\n",
    "            fig = sns.heatmap(df.iloc[:-1, :].T, annot=True).get_figure()\n",
    "            fig.savefig(str(path) + \"/\" + str(self.clf)[:-2] + \"class_report.pgf\") \n",
    "        else: \n",
    "            sns.heatmap(df.iloc[:-1, :].T, annot=True)\n",
    "\n",
    "    def store_best_estimator(self, path):\n",
    "        dump(self.grid.best_estimator_, path)\n",
    "\n",
    "def takeSecond(elem):\n",
    "    return elem[1]\n",
    "    \n",
    "def pca_transform(n_components, x):\n",
    "    pca = PCA(n_components=n_components)\n",
    "    pca.fit(x)\n",
    "    return pca.transform(x)\n",
    "\n",
    "def scaler_transform(x):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x)\n",
    "    return scaler.transform(x)\n",
    "\n",
    "estimators = [LinearSVC(), KNeighborsClassifier(), DecisionTreeClassifier(), RandomForestClassifier()]\n",
    "# estimators = [DecisionTreeClassifier()]\n",
    "estimator_params = [\n",
    "    {\n",
    "        \"loss\": ['hinge', 'squared_hinge'],\n",
    "        \"multi_class\": ['ovr', 'crammer_singer'],\n",
    "        \"max_iter\": [2000]\n",
    "    },\n",
    "    {\n",
    "        \"n_neighbors\": range(1,5,1),\n",
    "        \"weights\": [\"uniform\", \"distance\"],\n",
    "        \"algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"],\n",
    "        \"n_jobs\": [-1]\n",
    "    },\n",
    "    {\n",
    "        \"criterion\": ['gini', 'entropy'],\n",
    "        \"max_depth\": [6, 10, 12, 15],\n",
    "        \"min_samples_split\": range(2,10),\n",
    "        \"min_samples_leaf\": range(2,10)\n",
    "    },\n",
    "   {\n",
    "        \"n_estimators\": [60, 80, 100, 150],\n",
    "        \"criterion\": [\"log_loss\", \"gini\", \"entropy\"],\n",
    "        \"max_depth\": [6, 10, 12, 15], \n",
    "        \"min_samples_leaf\": [2, 4, 6],\n",
    "        \"min_samples_split\": [2, 4, 6]\n",
    "    },\n",
    "]\n",
    "\n",
    "def train_evaluate_estimators_gridsearch(x, y, estimators, estimator_params, scaling=None, pca=None):\n",
    "    path = \"\"\n",
    "    if scaling: \n",
    "        print(\"scaling...\")\n",
    "        x = scaler_transform(x)\n",
    "        path = path + \"scaled_\"\n",
    "    \n",
    "    if pca:\n",
    "        print(\"PCA...\")\n",
    "        path = path + \"pca_\"\n",
    "        x = pca_transform(4, x)\n",
    "\n",
    "    if pca==None and scaling==None:\n",
    "        path=\"GridSearchSklearn\"\n",
    "\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "\n",
    "    results = []\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, shuffle=True, test_size=0.2)\n",
    "    # x_train.to_csv(\"train_data.csv\", index=False)\n",
    "    # y_train.to_csv(\"train_labels.csv\", index=False)\n",
    "    # x_test.to_csv(\"test_data.csv\", index=False)\n",
    "    # y_test.to_csv(\"test_labels.csv\", index=False)\n",
    "    x_train = pd.read_csv(\"train_data.csv\")\n",
    "    x_test = pd.read_csv(\"test_data.csv\")\n",
    "    y_train = pd.read_csv(\"train_labels.csv\")\n",
    "    y_test = pd.read_csv(\"test_labels.csv\")\n",
    "    y_test = y_test.to_numpy()\n",
    "    y_test = y_test.reshape(y_test.shape[0],)\n",
    "    y_train = y_train.to_numpy()\n",
    "    y_train = y_train.reshape(y_train.shape[0],)\n",
    "\n",
    "    for estimator, estimator_params in zip(estimators, estimator_params):\n",
    "        store_path = path + \"_\" + str(estimator)[:-2]\n",
    "        grid = GridSearch(clf=estimator, params=estimator_params)\n",
    "        print(str(store_path) + \" is training...\")\n",
    "        if type(estimator) == type(LinearSVC()):\n",
    "            nystroem_transfomer = Nystroem(gamma=.2, random_state=1, n_components=3000)\n",
    "            train_transformed = nystroem_transfomer.fit_transform(x_train)\n",
    "            grid.train(train_transformed,y_train)\n",
    "        else:\n",
    "            grid.train(x_train,y_train)\n",
    "\n",
    "        grid.plot_classification_result(x_test,y_test, save=True, path=path)\n",
    "        grid.plot_selection_process(save=True, path=path)\n",
    "        if type(estimator) == type(LinearSVC()):\n",
    "            test_transformed = nystroem_transfomer.transform(x_test)\n",
    "            test_start = time.time()\n",
    "            test_score = grid.grid.score(test_transformed,y_test)\n",
    "            test_time = time.time() - test_start\n",
    "        else:\n",
    "            test_start = time.time()\n",
    "            test_score = grid.grid.score(x_test,y_test)\n",
    "            test_time = time.time() - test_start\n",
    "\n",
    "        clf = estimator\n",
    "        clf.set_params(**grid.grid.best_params_)\n",
    "        single_clf_start = time.time()\n",
    "        clf.fit(x,y)\n",
    "        single_clf_time = time.time() - single_clf_start\n",
    "        result_dict = {\n",
    "            \"scaling\": scaling,\n",
    "            \"pca\": pca,\n",
    "            \"estimator\": str(estimator),\n",
    "            \"best_score\": grid.grid.best_score_,\n",
    "            \"best_params\": grid.grid.best_params_,\n",
    "            \"test_score\": test_score,\n",
    "            \"train_time\": grid.elapsed_time,\n",
    "            \"test_time\": test_time,\n",
    "            \"single_estimator_with_best_params_training_time\": single_clf_time,\n",
    "        }\n",
    "        results.append(result_dict)\n",
    "        grid.store_best_estimator(path + \"/\" + store_path + \".joblib\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../static_merged_data.csv\")\n",
    "x = df.drop(\"status\", axis=1)\n",
    "y = df[\"status\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_process(x, y, estimators, estimator_params):\n",
    "    results = train_evaluate_estimators_gridsearch(x,y,estimators, estimator_params)\n",
    "    with open('ergebnisse.txt', 'a') as f:\n",
    "        f.write(\"\\n\\n\")\n",
    "        f.write(\"::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
    "        sorted_list = []\n",
    "        for params in results:\n",
    "            f.write(str(params))\n",
    "            f.write(\"\\n\\n\")\n",
    "            sorted_list.append((params[\"estimator\"], params[\"best_score\"]))\n",
    "        \n",
    "        sorted_list.sort(key=takeSecond)\n",
    "        sorted_list.sort(reverse=True)\n",
    "        f.write(\"----- Best estimator-----\\n\")\n",
    "        for idx,element in enumerate(sorted_list):\n",
    "            print(str(element[0]) + \"-> best_score: \" + str(element[1]*100) + \"%\\n\")\n",
    "\n",
    "    # pca_results = train_evaluate_estimators_gridsearch(x,y,estimators, estimator_params, pca=True)\n",
    "    # with open('results.txt', 'a') as f:\n",
    "    #     f.write(\"\\n\\n\")\n",
    "    #     f.write(\"::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
    "    #     sorted_list = []\n",
    "    #     for params in pca_results:\n",
    "    #         f.write(str(params))\n",
    "    #         f.write(\"\\n\\n\")\n",
    "    #         sorted_list.append((params[\"estimator\"], params[\"best_score\"]))\n",
    "        \n",
    "    #     sorted_list.sort(key=takeSecond)\n",
    "    #     f.write(\"----- Best estimator-----\\n\")\n",
    "    #     for idx,element in enumerate(sorted_list):\n",
    "    #         print(str(idx+1) + \". \" + str(element[0]) + \"-> accuracy: \" + str(element[1]*100) + \"%\\n\")\n",
    "\n",
    "    # scale_results = train_evaluate_estimators_gridsearch(x,y,estimators, estimator_params,scaling=True)\n",
    "    # with open('results.txt', 'a') as f:\n",
    "    #     f.write(\"\\n\\n\")\n",
    "    #     f.write(\"::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
    "    #     sorted_list = []\n",
    "    #     for params in scale_results:\n",
    "    #         f.write(str(params))\n",
    "    #         f.write(\"\\n\\n\")\n",
    "    #         sorted_list.append((params[\"estimator\"], params[\"best_score\"]))\n",
    "        \n",
    "    #     sorted_list.sort(key=takeSecond)\n",
    "    #     f.write(\"----- Best estimator-----\\n\")\n",
    "    #     for idx,element in enumerate(sorted_list):\n",
    "    #         print(str(idx+1) + \". \" + str(element[0]) + \"-> accuracy: \" + str(element[1]*100) + \"%\\n\")\n",
    "\n",
    "    # results = train_evaluate_estimators_gridsearch(x,y,estimators, estimator_params)\n",
    "    # with open('results.txt', 'a') as f:\n",
    "    #     f.write(\"\\n\\n\")\n",
    "    #     f.write(\"::::::::::::::::::::::::::::::::::::::::::::::::::\\n\")\n",
    "    #     sorted_list = []\n",
    "    #     for params in results:\n",
    "    #         f.write(str(params))\n",
    "    #         f.write(\"\\n\\n\")\n",
    "    #         sorted_list.append((params[\"estimator\"], params[\"best_score\"]))\n",
    "        \n",
    "    #     sorted_list.sort(key=takeSecond)\n",
    "    #     f.write(\"----- Best estimator-----\\n\")\n",
    "    #     for idx,element in enumerate(sorted_list):\n",
    "    #         f.write(str(3-idx) + \". \" + str(element[0]) + \"-> accuracy: \" + str(element[1]*100) + \"%\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchSklearn_LinearSVC is training...\n",
      "Fitting 10 folds for each of 4 candidates, totalling 40 fits\n"
     ]
    }
   ],
   "source": [
    "evaluation_process(x,y,estimators, estimator_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "\n",
    "dt = load(filename=\"./scaled_/scaled_DecisionTreeClassifier.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.kernel_approximation import Nystroem\n",
    "from sklearn.svm import LinearSVC\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "train_data = pd.read_csv(\"train_data.csv\")\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "test_data = pd.read_csv(\"test_data.csv\")\n",
    "test_labels = pd.read_csv(\"test_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(77079,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = train_labels.to_numpy()\n",
    "labels.shape\n",
    "labels  = labels.reshape(77079,)\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.99662688, 0.99617281, 0.99747016, 0.99682148, 0.99695102])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LinearSVC()\n",
    "feature_map = Nystroem(gamma=.2, random_state=1, n_components=3000)\n",
    "data_transformed = feature_map.fit_transform(train_data)\n",
    "cross_val_score(clf,data_transformed, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.997145822522055"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(data_transformed, labels)\n",
    "test_transformed = feature_map.transform(test_data)\n",
    "testing = test_labels.to_numpy()\n",
    "testing = testing.reshape(testing.shape[0],)\n",
    "clf.score(test_transformed, testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "def get_gzipped_model_size(file):\n",
    "  # Returns size of gzipped model, in bytes.\n",
    "  _, zipped_file = tempfile.mkstemp('.zip')\n",
    "  with zipfile.ZipFile(zipped_file, 'w', compression=zipfile.ZIP_DEFLATED) as f:\n",
    "    f.write(file)\n",
    "\n",
    "  return os.path.getsize(zipped_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier: 6440 bytes\n",
      "KNeighborsClassifier: 639006 bytes\n",
      "LinearSVC: 1044 bytes\n",
      "RandomForestClassifier: 623435 bytes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for clf in os.listdir(\"GridSearchSklearn\"):\n",
    "    if clf[-6:] == \"joblib\":\n",
    "        path = os.path.join(\"GridSearchSklearn\", clf)\n",
    "        print(clf[17:-7] + \": \" + str(get_gzipped_model_size(path)) + \" bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca1c6f47e78944e5b11f7d3b44b6206ab4f171b310471b46fba50959eb66c8df"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
